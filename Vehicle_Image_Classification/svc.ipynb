{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huynh\\Anaconda3\\envs\\python3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import scale, minmax_scale, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21186, 47)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "X = np.loadtxt('train.dat')\n",
    "y = np.loadtxt('train.labels')\n",
    "\n",
    "X_R_test = np.loadtxt('test.dat')\n",
    "\n",
    "# X = np.delete(X,[0,17,35],1)\n",
    "X = np.delete(X,[24],1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    f11 = f1_score(y_test, y_pred, average = 'micro')\n",
    "    return y_pred, f11\n",
    "\n",
    "def SVC_classifier(skf, c=0.2, gamma=100, n_components=8, dr='pca'):\n",
    "\n",
    "    f11_sum = 0\n",
    "    model = SVC(C=c, gamma=gamma, random_state=0, decision_function_shape='ovr',kernel='rbf',max_iter = -1)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "#         scale(X_train, axis = 1, copy = False)\n",
    "#         scale(X_test, axis = 1,copy = False)\n",
    "\n",
    "#         if dr == 'pca':\n",
    "#             pca = PCA(n_components=n_components, iterated_power=100)\n",
    "#             X_train_reduced = pca.fit_transform(X_train)\n",
    "#             X_test_reduced = pca.fit_transform(X_test)\n",
    "\n",
    "#         elif dr == 'svd':\n",
    "#             svd = TruncatedSVD(n_components=n_components, n_iter=1000, random_state=42)\n",
    "#             X_train_reduced = svd.fit_transform(X_train)\n",
    "#             X_test_reduced = svd.fit_transform(X_test)\n",
    "\n",
    "#         elif dr == 'lle':\n",
    "#             lle = LocallyLinearEmbedding(n_components=n_components, random_state=42)\n",
    "#             X_train_reduced = lle.fit_transform(X_train)\n",
    "#             X_test_reduced = lle.fit_transform(X_test) \n",
    "        \n",
    "#         scale(X_train_reduced, axis = 1, copy = False)\n",
    "#         scale(X_test_reduced, axis = 1,copy = False)\n",
    "\n",
    "        # model\n",
    "#         model.fit(X_train_reduced, y_train)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # predict\n",
    "#         y_pred, f11 = make_prediction(model, X_test_reduced, y_test)\n",
    "        y_pred, f11 = make_prediction(model, X_test, y_test)\n",
    "        print('weighted: ', f11)\n",
    "\n",
    "        f11_sum += f11\n",
    "\n",
    "    f11 = f11_sum/5\n",
    "    \n",
    "\n",
    "    \n",
    "    return f11, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_score = 0\n",
    "# best_i_j = 0\n",
    "\n",
    "# c = [1.9]\n",
    "# gamma = [70,75,80]\n",
    "\n",
    "# for i in range(len(c)):\n",
    "#     for j in range(len(gamma)):\n",
    "#         f11, model = SVC_classifier(skf, c=c[i], gamma=gamma[j], dr='svd')\n",
    "#         if f11 >= best_score:\n",
    "#             best_score = f11\n",
    "#             best_i_j_k = [c[i], gamma[j]]\n",
    "#         print(best_score, c[i], gamma[j])\n",
    "        \n",
    "# print(best_i_j_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dr = TruncatedSVD(n_components=best_i_j_k[2], n_iter=7, random_state=42)\n",
    "# dr = PCA(n_components=best_i_j_k[2])\n",
    "\n",
    "# X_reduced = dr.fit_transform(X)\n",
    "# X_R_test_reduced = dr.fit_transform(X_R_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SVC(C=c, gamma=gamma, random_state=0, decision_function_shape='ovr',kernel='rbf',max_iter = -1)\n",
    "# model.fit(X_reduced, y)\n",
    "\n",
    "# pred = model.predict(X_R_test_reduced)\n",
    "\n",
    "# with open(\"result.dat\", \"w\") as f: \n",
    "#     for i in pred:\n",
    "#         f.write(str(int(i)))\n",
    "#         f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_R_test_reduced = np.delete(X_R_test,[24],1)\n",
    "model = SVC(C=1.9, gamma=70, random_state=0, decision_function_shape='ovr',kernel='rbf',max_iter = -1)\n",
    "model.fit(X, y)\n",
    "\n",
    "pred = model.predict(X_R_test_reduced)\n",
    "\n",
    "with open(\"result.dat\", \"w\") as f: \n",
    "    for i in pred:\n",
    "        f.write(str(int(i)))\n",
    "        f.write('\\n')\n",
    "        \n",
    "# 0.7164661861234071 1.9 70 / 0 17 35 /24 best\n",
    "# 1.8 75 ovr 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DECISION TREE\n",
    "\n",
    "# # coding: utf-8\n",
    "\n",
    "# # In[1]:\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA, TruncatedSVD\n",
    "# from sklearn.preprocessing import scale, MinMaxScaler\n",
    "# from sklearn.model_selection import KFold, StratifiedKFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# # In[2]:\n",
    "\n",
    "\n",
    "# # read data\n",
    "# X = np.loadtxt('train.dat')\n",
    "# y = np.loadtxt('train.labels')\n",
    "\n",
    "# X_R_test = np.loadtxt('test.dat')\n",
    "\n",
    "\n",
    "# # In[3]:\n",
    "\n",
    "\n",
    "# def make_prediction(model, X_test, y_test):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     f11 = f1_score(y_test, y_pred, average = 'micro')\n",
    "#     return y_pred, f11\n",
    "\n",
    "# def DT_classifier(skf, criterion='gini', max_depth=10, n_components=8, dr='pca'):\n",
    "\n",
    "#     f11_sum = 0\n",
    "#     model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, splitter='best', random_state=0)\n",
    "\n",
    "#     for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# #         scale(X_train, copy = False)\n",
    "# #         scale(X_test, copy = False)\n",
    "# #         scaler1 = MinMaxScaler()\n",
    "# #         scaler2 = MinMaxScaler()\n",
    "# #         scaler1.fit_transform(X_train)\n",
    "# #         scaler2.fit_transform(X_test)\n",
    "\n",
    "# #         if dr == 'pca':\n",
    "# #             pca = PCA(n_components=n_components)\n",
    "# #             X_train_reduced = pca.fit_transform(X_train)\n",
    "# #             X_test_reduced = pca.fit_transform(X_test)\n",
    "\n",
    "# #         elif dr == 'svd':\n",
    "# #             svd = TruncatedSVD(n_components=n_components, n_iter=7, random_state=42)\n",
    "# #             X_train_reduced = svd.fit_transform(X_train)\n",
    "# #             X_test_reduced = svd.fit_transform(X_test)\n",
    "#         # model\n",
    "#         model.fit(X_train, y_train)\n",
    "\n",
    "#         # predict\n",
    "#         y_pred, f11 = make_prediction(model, X_test, y_test)\n",
    "#         print('weighted: ', f11)\n",
    "\n",
    "#         f11_sum += f11\n",
    "\n",
    "#     f11 = f11_sum/5\n",
    "    \n",
    "\n",
    "    \n",
    "#     return f11, model\n",
    "\n",
    "\n",
    "# # In[4]:\n",
    "\n",
    "\n",
    "# skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "\n",
    "# # In[5]:\n",
    "\n",
    "\n",
    "# best_score = 0\n",
    "# best_i_j = 0\n",
    "\n",
    "# criterion = ['gini','entropy']\n",
    "# max_depth = [15,8,10,20,25]\n",
    "# n_components = [8]\n",
    "# for i in range(len(criterion)):\n",
    "#     for j in range(len(max_depth)):\n",
    "#         for k in range(len(n_components)):\n",
    "#             f11, model = DT_classifier(skf, criterion=criterion[i], max_depth=max_depth[j], n_components=n_components[k], dr='pca')\n",
    "#             if f11 >= best_score:\n",
    "#                 best_score = f11\n",
    "#                 best_i_j_k = [criterion[i], max_depth[j], n_components[k]]\n",
    "#             print(best_score, criterion[i], max_depth[j], n_components[k])\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# # dr = TruncatedSVD(n_components=best_i_j_k[2], n_iter=7, random_state=42)\n",
    "# # # dr = PCA(n_components=best_i_j_k[2])\n",
    "\n",
    "# # X_reduced = dr.fit_transform(X)\n",
    "# # X_R_test_reduced = dr.fit_transform(X_R_test)\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# # model = RandomForestClassifier(n_estimators=best_i_j_k[0], max_depth=best_i_j_k[1], random_state=0)\n",
    "# # model.fit(X_reduced, y)\n",
    "\n",
    "# # pred = model.predict(X_R_test_reduced)\n",
    "\n",
    "# # with open(\"result.dat\", \"w\") as f: \n",
    "# #     for i in pred:\n",
    "# #         f.write(str(int(i)))\n",
    "# #         f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # KNN\n",
    "\n",
    "# # coding: utf-8\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA, TruncatedSVD\n",
    "# from sklearn.preprocessing import scale, MinMaxScaler,minmax_scale\n",
    "# from sklearn.model_selection import KFold, StratifiedKFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# # read data\n",
    "# X = np.loadtxt('train.dat')\n",
    "# y = np.loadtxt('train.labels')\n",
    "\n",
    "# X_R_test = np.loadtxt('test.dat')\n",
    "# X1 = np.delete(X,[8,24],1)\n",
    "# # X = np.delete(X,list(range(1))+list(range(16,17))+list(range(32,33)),1)\n",
    "# # ilist = []\n",
    "# # for i in range(len(y)):\n",
    "# #     if y[i] == 10 or y[i] == 11: ilist.append(i)\n",
    "# # X = np.delete(X,ilist,0)\n",
    "# # y = np.delete(y,ilist,0)\n",
    "\n",
    "# X.shape\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# def make_prediction(model, X_test, y_test):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     f11 = f1_score(y_test, y_pred, average = 'micro')\n",
    "#     return y_pred, f11\n",
    "\n",
    "# def KNN_classifier(skf, k, n_components = 30, dr = 'pca'):\n",
    "\n",
    "#     f11_sum = 0\n",
    "#     model = KNeighborsClassifier(n_neighbors=k, n_jobs=-1, weights='distance')\n",
    "\n",
    "#     for train_index, test_index in skf.split(X1, y):\n",
    "\n",
    "#         X_train, X_test = X1[train_index], X1[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# #         minmax_scale(X_train,axis=0, copy = False)\n",
    "# #         minmax_scale(X_test,axis=0, copy = False)\n",
    "\n",
    "# #         if dr == 'pca':\n",
    "# #             pca = PCA(n_components=n_components)\n",
    "# #             X_train_reduced = pca.fit_transform(X_train)\n",
    "# #             X_test_reduced = pca.fit_transform(X_test)\n",
    "\n",
    "# #         elif dr == 'svd':\n",
    "# #             svd = TruncatedSVD(n_components=n_components, n_iter=100, algorithm='arpack',random_state=42)\n",
    "# #             X_train_reduced = svd.fit_transform(X_train)\n",
    "# #             X_test_reduced = svd.fit_transform(X_test)\n",
    "\n",
    "# #         elif dr == 'lle':\n",
    "# #             lle = LocallyLinearEmbedding(n_components=n_components, random_state=42)\n",
    "# #             X_train_reduced = lle.fit_transform(X_train)\n",
    "# #             X_test_reduced = lle.fit_transform(X_test)\n",
    "            \n",
    "# #         minmax_scale(X_train_reduced,axis=0, copy = False)\n",
    "# #         minmax_scale(X_test_reduced,axis=0, copy = False)\n",
    "#         # model\n",
    "# #         model.fit(X_train_reduced, y_train)\n",
    "#         model.fit(X_train, y_train)\n",
    "\n",
    "#         # predict\n",
    "# #         y_pred, f11 = make_prediction(model, X_test_reduced, y_test)\n",
    "#         y_pred, f11 = make_prediction(model, X_test, y_test)\n",
    "#         print('weighted: ', f11)\n",
    "\n",
    "#         f11_sum += f11\n",
    "\n",
    "#     f11 = f11_sum/5\n",
    "    \n",
    "\n",
    "    \n",
    "#     return f11, model\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# best_score = 0\n",
    "# best_i_j = 0\n",
    "\n",
    "# k = [6,7,8]\n",
    "# n_components = [1]\n",
    "# for i in range(len(k)):\n",
    "#     for j in range(len(n_components)):\n",
    "#         f11, model = KNN_classifier(skf, k=k[i], n_components=n_components[j], dr='svd')\n",
    "    \n",
    "#         if f11 >= best_score:\n",
    "#             best_score = f11\n",
    "#             best_i_j = [k[i], n_components[j]]\n",
    "#         print(best_score, k[i], n_components[j])\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# # print(best_score)\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# # print(best_i_j)\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "# # pca = PCA(n_components=best_i_j[1])\n",
    "# # X_reduced = pca.fit_transform(X)\n",
    "# # X_R_test_reduced = pca.fit_transform(X_R_test)\n",
    "\n",
    "# # model = KNeighborsClassifier(n_neighbors=best_i_j[0], n_jobs=-1)\n",
    "# # model.fit(X_reduced, y)\n",
    "\n",
    "# # pred = model.predict(X_R_test_reduced)\n",
    "\n",
    "# # with open(\"result.dat\", \"w\") as f: \n",
    "# #     for i in pred:\n",
    "# #         f.write(str(int(i)))\n",
    "# #         f.write('\\n')\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# # svd = TruncatedSVD(n_components=best_i_j[1], n_iter=7, random_state=42)\n",
    "# # X_reduced = svd.fit_transform(X)\n",
    "# # X_R_test_reduced = svd.fit_transform(X_R_test)\n",
    "\n",
    "# # model = KNeighborsClassifier(n_neighbors=best_i_j[0], n_jobs=-1)\n",
    "# # model.fit(X_reduced, y)\n",
    "\n",
    "# # pred = model.predict(X_R_test_reduced)\n",
    "\n",
    "# # with open(\"result.dat\", \"w\") as f: \n",
    "# #     for i in pred:\n",
    "# #         f.write(str(int(i)))\n",
    "# #         f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLP\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA, TruncatedSVD\n",
    "# from sklearn.preprocessing import scale, MinMaxScaler\n",
    "# from sklearn.model_selection import KFold, StratifiedKFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# # In[2]:\n",
    "\n",
    "\n",
    "# # read data\n",
    "# X = np.loadtxt('train.dat')\n",
    "# y = np.loadtxt('train.labels')\n",
    "\n",
    "# X_R_test = np.loadtxt('test.dat')\n",
    "\n",
    "\n",
    "# # In[3]:\n",
    "\n",
    "\n",
    "# def make_prediction(model, X_test, y_test):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     f11 = f1_score(y_test, y_pred, average = 'micro')\n",
    "#     return y_pred, f11\n",
    "\n",
    "# def MLP_classifier(skf, hidden_layer_sizes=(5,3),max_iter=200,n_components=8, dr='pca'):\n",
    "\n",
    "#     f11_sum = 0\n",
    "#     model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,learning_rate_init=0.0001,max_iter=max_iter)\n",
    "\n",
    "#     for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# #         scale(X_train, copy = False)\n",
    "# #         scale(X_test, copy = False)\n",
    "# #         scaler1 = MinMaxScaler()\n",
    "# #         scaler2 = MinMaxScaler()\n",
    "# #         scaler1.fit_transform(X_train)\n",
    "# #         scaler2.fit_transform(X_test)\n",
    "\n",
    "#         if dr == 'pca':\n",
    "#             pca = PCA(n_components=n_components)\n",
    "#             X_train_reduced = pca.fit_transform(X_train)\n",
    "#             X_test_reduced = pca.fit_transform(X_test)\n",
    "\n",
    "#         elif dr == 'svd':\n",
    "#             svd = TruncatedSVD(n_components=n_components, n_iter=7, random_state=42)\n",
    "#             X_train_reduced = svd.fit_transform(X_train)\n",
    "#             X_test_reduced = svd.fit_transform(X_test)\n",
    "#         # model\n",
    "#         model.fit(X_train_reduced, y_train)\n",
    "\n",
    "#         # predict\n",
    "#         y_pred, f11 = make_prediction(model, X_test_reduced, y_test)\n",
    "#         print('weighted: ', f11)\n",
    "\n",
    "#         f11_sum += f11\n",
    "\n",
    "#     f11 = f11_sum/5\n",
    "    \n",
    "\n",
    "    \n",
    "#     return f11, model\n",
    "\n",
    "\n",
    "# # In[4]:\n",
    "\n",
    "\n",
    "# skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# best_score = 0\n",
    "# best_i_j = 0\n",
    "\n",
    "# hidden_layer_sizes = [(15),(20,5)]\n",
    "# max_iter = [500, 800, 1000]\n",
    "# n_components = [20]\n",
    "# for i in range(len(hidden_layer_sizes)):\n",
    "#     for j in range(len(max_iter)):\n",
    "#         for k in range(len(n_components)):\n",
    "#             f11, model = MLP_classifier(skf, hidden_layer_sizes=hidden_layer_sizes[i], max_iter=max_iter[j], n_components=n_components[k], dr='svd')\n",
    "#             if f11 >= best_score:\n",
    "#                 best_score = f11\n",
    "#                 best_i_j_k = [hidden_layer_sizes[i], max_iter[j], n_components[k]]\n",
    "#             print(best_score, hidden_layer_sizes[i], max_iter[j], n_components[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RFT\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA, TruncatedSVD\n",
    "# from sklearn.preprocessing import scale, MinMaxScaler\n",
    "# from sklearn.model_selection import KFold, StratifiedKFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "\n",
    "# # In[2]:\n",
    "\n",
    "\n",
    "# # read data\n",
    "# X = np.loadtxt('train.dat')\n",
    "# y = np.loadtxt('train.labels')\n",
    "\n",
    "\n",
    "# X_R_test = np.loadtxt('test.dat')\n",
    "\n",
    "\n",
    "# # In[3]:\n",
    "\n",
    "\n",
    "# def make_prediction(model, X_test, y_test):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     f11 = f1_score(y_test, y_pred, average = 'micro')\n",
    "#     return y_pred, f11\n",
    "\n",
    "# def RFT_classifier(skf, n_estimators=100, max_depth=2, n_components=8, dr='pca'):\n",
    "\n",
    "#     f11_sum = 0\n",
    "#     model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=0)\n",
    "\n",
    "#     for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# #         scale(X_train, copy = False)\n",
    "# #         scale(X_test, copy = False)\n",
    "# #         scaler1 = MinMaxScaler()\n",
    "# #         scaler2 = MinMaxScaler()\n",
    "# #         scaler1.fit_transform(X_train)\n",
    "# #         scaler2.fit_transform(X_test)\n",
    "\n",
    "#         if dr == 'pca':\n",
    "#             pca = PCA(n_components=n_components)\n",
    "#             X_train_reduced = pca.fit_transform(X_train)\n",
    "#             X_test_reduced = pca.fit_transform(X_test)\n",
    "\n",
    "#         elif dr == 'svd':\n",
    "#             svd = TruncatedSVD(n_components=n_components, n_iter=7, random_state=42)\n",
    "#             X_train_reduced = svd.fit_transform(X_train)\n",
    "#             X_test_reduced = svd.fit_transform(X_test)\n",
    "            \n",
    "#         elif dr == 'lle':\n",
    "#             lle = LocallyLinearEmbedding(n_components=n_components, random_state=42)\n",
    "#             X_train_reduced = lle.fit_transform(X_train)\n",
    "#             X_test_reduced = lle.fit_transform(X_test)\n",
    "#         # model\n",
    "#         model.fit(X_train, y_train)\n",
    "\n",
    "#         # predict\n",
    "#         y_pred, f11 = make_prediction(model, X_test, y_test)\n",
    "#         print('weighted: ', f11)\n",
    "\n",
    "#         f11_sum += f11\n",
    "\n",
    "#     f11 = f11_sum/5\n",
    "    \n",
    "\n",
    "    \n",
    "#     return f11, model\n",
    "\n",
    "\n",
    "# # In[4]:\n",
    "\n",
    "\n",
    "# skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "\n",
    "# # In[5]:\n",
    "\n",
    "\n",
    "# best_score = 0\n",
    "# best_i_j = 0\n",
    "\n",
    "# n_estimators = [200,400]\n",
    "# max_depth = [300]\n",
    "# n_components = [8]\n",
    "# for i in range(len(n_estimators)):\n",
    "#     for j in range(len(max_depth)):\n",
    "#         for k in range(len(n_components)):\n",
    "#             f11, model = RFT_classifier(skf, n_estimators=n_estimators[i], max_depth=max_depth[j], n_components=n_components[k], dr='svod')\n",
    "#             if f11 >= best_score:\n",
    "#                 best_score = f11\n",
    "#                 best_i_j_k = [n_estimators[i], max_depth[j], n_components[k]]\n",
    "#             print(best_score, n_estimators[i], max_depth[j], n_components[k])\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# # dr = TruncatedSVD(n_components=best_i_j_k[2], n_iter=7, random_state=42)\n",
    "# # # dr = PCA(n_components=best_i_j_k[2])\n",
    "\n",
    "# # X_reduced = dr.fit_transform(X)\n",
    "# # X_R_test_reduced = dr.fit_transform(X_R_test)\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# # model = RandomForestClassifier(n_estimators=best_i_j_k[0], max_depth=best_i_j_k[1], random_state=0)\n",
    "# # model.fit(X_reduced, y)\n",
    "\n",
    "# # pred = model.predict(X_R_test_reduced)\n",
    "\n",
    "# # with open(\"result.dat\", \"w\") as f: \n",
    "# #     for i in pred:\n",
    "# #         f.write(str(int(i)))\n",
    "# #         f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
